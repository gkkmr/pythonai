{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ImartVaccine_Usage_Prediction.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"3OXjYS1webna"},"source":["## Problem Statement\n","\n","The data set is the response of people to the h1n1 flu vaccine related questionnaire. The respondents are people of age 6 months and older. This survey was designed to monitor the influenza immunization coverage in 2009-10 season. Machine learning techniques may aid a more efficient analysis in the prediction of how likely the people are to opt for the flu vaccine. In this case study, we predict, how likely it is that the people will take a H1N1 flu vaccine.        "]},{"cell_type":"markdown","metadata":{"id":"AQO22FFqebnb"},"source":["## Data Definition\n","\n","**unique_id**: Unique identifier for each respondent - (Numerical)    \n","\n","**h1n1_worry**: Worry about the h1n1 flu(0,1,2,3) 0=Not worried at all, 1=Not very worried, 2=Somewhat worried, 3=Very worried - (Categorical)\n","\n","**h1n1_awareness**: Signifies the amount of knowledge or understanding the respondent has about h1n1 flu - (0,1,2) - 0=No knowledge, 1=little knowledge, 2=good knowledge- (Categorical) \n"," \n","**antiviral_medication**: Has the respondent taken antiviral vaccination - (0,1) (Categorical)\n","    \n","**contact_avoidance**: Has avoided any close contact with people who have flu-like symptoms  - (0,1) - (Categorical)\n","    \n","**bought_face_mask**: Has the respondent bought mask or not - (0,1) - (Categorical)\n","    \n","**wash_hands_frequently**: Washes hands frequently or uses hand sanitizer - (0,1) - (Categorical)\n","    \n","**avoid_large_gatherings**: Has the respondent reduced time spent at large gatherings - (0,1) - (Categorical)\n","    \n","**reduced_outside_home_cont**: Has the respondent reduced contact with people outside own house - (0,1) - (Categorical)\n","    \n","**avoid_touch_face**: Avoids touching nose, eyes, mouth - (0,1) - (Categorical)\n","\n","**dr_recc_h1n1_vacc**: Doctor has recommended h1n1 vaccine - (0,1) - (Categorical)\n","    \n","**dr_recc_seasonal_vacc**: Doctor has recommended seasonalflu vaccine - (0,1) - (Categorical)\n","    \n","**chronic_medic_condition**: Has any chronic medical condition - (0,1) - (Categorical)\n","    \n","**cont_child_undr_6_mnth** - Has a regular contact with child the age of 6 months - (0,1) - (Categorical)\n","\n","**is_health_worker**: Is respondent a health worker - (0,1) - (Categorical)\n","    \n","**has_health_insur**: Does respondent have health insurance - (0,1) - (Categorical)\n","    \n","**is_h1n1_vacc_effective**:  Does respondent think that the h1n1 vaccine is effective - (1,2,3,4,5)- (1=Thinks not effective at all, 2=Thinks it is not very effective, 3=Doesn't know if it is effective or not, 4=Thinks it is somewhat effective, 5=Thinks it is highly effective) - (Categorical)\n","\n","**is_h1n1_risky**: What respondenst think about the risk of getting ill with h1n1 in the absence of the vaccine- (1,2,3,4,5)- (1=Thinks it is not very low risk, 2=Thinks it is somewhat low risk, 3=Doesn't know if it is risky or not, 4=Thinks it is somewhat high risk, 5=Thinks it is very highly risky) - (Categorical)\n"," \n","**sick_from_h1n1_vacc**: Does respondent worry about getting sick by taking the h1n1 vaccine - (1,2,3,4,5)- (1=Respondent not worried at all, 2=Respondent is not very worried, 3=Doesn't know, 4=Respondent is somewhat worried, 5Respondent is very worried) - (Categorical)\n","\n","**is_seas_vacc_effective**: Does respondent think that the seasonal vaccine is effective- (1,2,3,4,5)- (1=Thinks not effective at all, 2=Thinks it is not very effective, 3=Doesn't know if it is effective or not, 4=Thinks it is somewhat effective, 5=Thinks it is highly effective) - (Categorical)\n","\n","**is_seas_flu_risky**: What respondenst think about the risk of getting ill with seasonal flu in the absence of the vaccine- (1,2,3,4,5)- (1=Thinks it is not very low risk, 2=Thinks it is somewhat low risk, 3=Doesn't know if it is risky or not, 4=Thinks it is somewhat high risk, 5=Thinks it is very highly risky) - (Categorical)\n"," \n","**sick_from_seas_vacc**: Does respondent worry about getting sick by taking the seasonal flu vaccine - (1,2,3,4,5)- (1=Respondent not worried at all, 2=Respondent is not very worried, 3=Doesn't know, 4=Respondent is somewhat worried, 5Respondent is very worried) - (Categorical)\n","\n","**age_bracket** - Age bracket of the respondent - (18 - 34 Years, 35 - 44 Years, 45 - 54 Years, 55 - 64 Years, 64+ Years) - (Categorical)\n","    \n","**qualification** - Qualification/education level of the respondent as per their response -(<12 Years, 12 Years, College Graduate, Some College) - (Categorical)\n","    \n","**race**: Respondent's race - (White, Black, Other or Multiple ,Hispanic) - (Categorical) \n","    \n","**sex**: Respondent's sex - (Female, Male) - (Categorical)\n","    \n","**income_level**:Annual income of the respondent as per the 2008 poverty Census - (<=$75000-Above Poverty, >$75000, Below Poverty) - (Categorical)\n","    \n","**marital_status**: Respondent's marital status - (Not Married, Married) - (Categorical)\n","    \n","**housing_status**: Respondent's housing status - (Own, Rent) - (Categorical)\n","    \n","**employment**: Respondent's employment status - (Not in Labor Force, Employed, Unemployed) - (Categorical)\n","    \n","**census_msa**: Residence of the respondent with the MSA(metropolitan statistical area)(Non-MSA, MSA-Not Principle, CityMSA-Principle city) - (Yes, no) - (Categorical)\n","    \n","**no_of_adults**:  Number of adults in the respondent's house (0,1,2,3) - (Yes, no) - (Categorical)\n","\n","**no_of_children**: Number of children in the respondent's house(0,1,2,3) - (Yes, No) - (Categorical)\n","\n","**h1n1_vaccine**: (Dependent variable)Did the respondent received the h1n1 vaccine or not(1,0) - (Yes, No) - (Categorical)"]},{"cell_type":"markdown","metadata":{"id":"AyalDMN-ebnc"},"source":["<a id='import_lib'></a>\n","# 1. Import Libraries"]},{"cell_type":"code","metadata":{"collapsed":true,"id":"lBgh1J0Mebnd","executionInfo":{"status":"ok","timestamp":1627189519853,"user_tz":-330,"elapsed":1786,"user":{"displayName":"Arunkumar Nair","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjgmWFCgJdcKJSRtC8oAFcB4vcjJSWC9JIuSLTgGQ=s64","userId":"14175196440623772817"}}},"source":["# suppress display of warnings\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","# 'Pandas' is used for data manipulation and analysis\n","import pandas as pd \n","\n","# 'Numpy' is used for mathematical operations on large, multi-dimensional arrays and matrices\n","import numpy as np\n","\n","# 'Matplotlib' is a data visualization library for 2D and 3D plots, built on numpy\n","import matplotlib.pyplot as plt\n","from matplotlib.colors import ListedColormap\n","\n","# 'Seaborn' is based on matplotlib; used for plotting statistical graphics\n","import seaborn as sns\n","\n","# import 'is_string_dtype' to check if the type of input is string  \n","from pandas.api.types import is_string_dtype\n","\n","# import various functions to perform classification\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import train_test_split\n","from sklearn import metrics\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import cohen_kappa_score\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import roc_auc_score\n","from sklearn.metrics import roc_curve\n","from sklearn.linear_model import SGDClassifier\n","\n","\n","# import functions to perform logistic regression\n","import statsmodels\n","import statsmodels.api as sm"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"collapsed":true,"id":"iO30fCK27vEo","executionInfo":{"status":"ok","timestamp":1627189519854,"user_tz":-330,"elapsed":11,"user":{"displayName":"Arunkumar Nair","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjgmWFCgJdcKJSRtC8oAFcB4vcjJSWC9JIuSLTgGQ=s64","userId":"14175196440623772817"}}},"source":["# set the plot size using 'rcParams'\n","# once the plot size is set using 'rcParams', it sets the size of all the forthcoming plots in the file\n","# pass width and height in inches to 'figure.figsize' \n","plt.rcParams['figure.figsize'] = [15,8]"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fHw0kQpbDQzv"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"Ll0ntaGOebng"},"source":["<a id='set_options'></a>\n","# 2. Set Options"]},{"cell_type":"code","metadata":{"collapsed":true,"id":"qJcw0J2Cebnh","executionInfo":{"status":"ok","timestamp":1627189519855,"user_tz":-330,"elapsed":9,"user":{"displayName":"Arunkumar Nair","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjgmWFCgJdcKJSRtC8oAFcB4vcjJSWC9JIuSLTgGQ=s64","userId":"14175196440623772817"}}},"source":["# display all columns of the dataframe\n","pd.options.display.max_columns = None\n","\n","# display all rows of the dataframe\n","pd.options.display.max_rows = None\n","\n","# use below code to convert the 'exponential' values to float\n","np.set_printoptions(suppress=True)"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yPb9_if1ebnl"},"source":["<a id='RD'></a>\n","# 3. Read Data"]},{"cell_type":"code","metadata":{"id":"wFzZeIzV8eYH"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fqVOXBQSExWF"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EOypBpEm8prK"},"source":["#root_path='/content/gdrive/MyDrive/Canspirit/h1n1_vaccine_prediction.csv'\n","root_path='/content/gdrive/MyDrive/Colab Notebooks/ImarticusArun/4LogisticsRegression/h1n1_vaccine_prediction.csv'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MDTwhMqAebnm"},"source":["# read the excel data file \n","df_vaccine = pd.read_csv(root_path)\n","\n","# display the top 5 rows of the dataframe\n","df_vaccine.head()\n","\n","# Note: To display more rows, example 10, use head(10)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Hlwcwgrz7vEt"},"source":["#### Dimensions of the data"]},{"cell_type":"code","metadata":{"id":"YvpgDFIA7vEt"},"source":["# 'shape' function gives the total number of rows and columns in the data\n","df_vaccine.shape"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SSHIYKY2ebns"},"source":["<a id='data_preparation'></a>\n","# 4. Data Analysis and Preparation"]},{"cell_type":"markdown","metadata":{"id":"Y-baDwGWebnu"},"source":["<a id='Data_Understanding'></a>\n","## 4.1 Understand the Dataset"]},{"cell_type":"markdown","metadata":{"id":"niAkAldS7vEw"},"source":["**1. Check for the data type**"]},{"cell_type":"code","metadata":{"id":"TnYrzq7Yebn4","scrolled":false},"source":["# 'dtypes' gives the data type for each column\n","df_vaccine.dtypes"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZWfobzqZ7vEx"},"source":["**2. Change the incorrect data type.**"]},{"cell_type":"code","metadata":{"collapsed":true,"id":"ogPgThuFebn8","scrolled":true},"source":["# use 'for' loop to change the data type of variables \n","for col in ['h1n1_worry','h1n1_awareness', 'antiviral_medication', 'contact_avoidance', 'bought_face_mask',\n","            'wash_hands_frequently', 'avoid_large_gatherings', 'reduced_outside_home_cont', 'avoid_touch_face', \n","            'dr_recc_h1n1_vacc', 'dr_recc_seasonal_vacc', 'chronic_medic_condition','cont_child_undr_6_mnths',\n","           'is_health_worker', 'has_health_insur', 'is_h1n1_vacc_effective', 'is_h1n1_risky', 'sick_from_h1n1_vacc', \n","            'is_seas_vacc_effective', 'is_seas_risky', 'sick_from_seas_vacc', 'no_of_adults', 'no_of_children']:\n","\n","    # use .astype() to change the data type\n","    df_vaccine[col] = df_vaccine[col].astype('object')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7rG9ZJ7bebn-"},"source":["**3. Recheck the data type after the conversion.**"]},{"cell_type":"code","metadata":{"id":"Zp6_mQOBebn_"},"source":["# recheck the data types of all variables\n","df_vaccine.dtypes"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"collapsed":true,"id":"WEFDLhoK7vEz"},"source":["#drop the field 'unique_id'\n","# axis=1: it stands for column\n","# inplace=True: it perform operations on original data\n","df_vaccine.drop('unique_id', axis=1, inplace=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dEupsywd7vEz"},"source":["#verify the shape\n","df_vaccine.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"collapsed":true,"id":"74cNHkpc7vE0"},"source":["# splitting features and the target variable\n","# consider all the columns except 'h1n1_vaccine' using 'iloc'\n","df_features = df_vaccine.iloc[:, df_vaccine.columns != 'h1n1_vaccine']\n","\n","# consider the target variable\n","df_target = df_vaccine.iloc[:, df_vaccine.columns == 'h1n1_vaccine']"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qNAIc-M17vE0"},"source":["Use the dataframe containing features (df_features) for further analysis."]},{"cell_type":"markdown","metadata":{"id":"BFOkFedXeboC"},"source":["<a id='Summary_Statistics'></a>\n","### 4.1.2 Summary Statistics"]},{"cell_type":"markdown","metadata":{"id":"RdrICjec7vE1"},"source":["**1. For numerical variables, use the describe()**"]},{"cell_type":"code","metadata":{"id":"BCq-Il09eboC","scrolled":true},"source":["# the describe() returns the statistical summary of the variables\n","# by default, it returns the summary of all categorical variables as tere are no numerical variables in the dataset\n","# use .transpose() for better readability, however its optional\n","df_features.describe().transpose()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nrjouuOP7vE2"},"source":["<a id='distribution_variables'></a>\n","### 4.1.3 Distribution of Variables"]},{"cell_type":"code","metadata":{"id":"G7HE9bl9eboz"},"source":["# create a list of all categorical variables\n","# initiate an empty list to store the categorical variables\n","categorical=[]\n","\n","# use for loop to check the data type of each variable\n","for column in df_features:\n","    \n","    # use 'if' statement with condition to check the categorical type \n","    if is_string_dtype(df_features[column]):\n","        \n","        # append the variables with 'categoric' data type in the list 'categorical'\n","        categorical.append(column)\n","\n","# plot the count plot for each categorical variable \n","# set the number of rows in the subplot using the parameter, 'nrows'\n","# set the number of columns in the subplot using the parameter, 'ncols'\n","# 'figsize' sets the figure size\n","fig, ax = plt.subplots(nrows = 8, ncols = 4, figsize=(25, 30))\n","\n","\n","# use for loop to plot the count plot for each variable\n","for variable, subplot in zip(categorical, ax.flatten()):\n","    \n","    # use countplot() to plot the graph\n","    # pass the axes for the plot to the parameter, 'ax'\n","    sns.countplot(df_vaccine[variable], ax = subplot)\n","\n","# display the plot\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sWFLPPl2yVAo"},"source":["df_vaccine[variable]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IpQ4SrAS7vE4"},"source":["#### 3. Distribution of dependent variable."]},{"cell_type":"code","metadata":{"id":"NYXAjl4I7vE5","scrolled":true},"source":["# get counts of 0's and 1's in the 'h1n1_vaccine' variable using 'value_counts()'\n","# store the values in 'class_frequency'\n","class_frequency = df_target.h1n1_vaccine.value_counts()\n","class_frequency"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kQPl4U5D7vE5","scrolled":false},"source":["# plot the countplot of the variable 'h1n1_vaccine'\n","sns.countplot(x = df_target.h1n1_vaccine)\n","\n","# use below code to print the values in the graph\n","# 'x' and 'y' gives position of the text\n","# 's' is the text on the plot\n","plt.text(x = -0.05, y = df_target.h1n1_vaccine.value_counts()[0] + 30, s = str((class_frequency[0])*100/len(df_target.h1n1_vaccine)) + '%')\n","plt.text(x = 0.95, y = df_target.h1n1_vaccine.value_counts()[1] +20, s = str((class_frequency[1])*100/len(df_target.h1n1_vaccine)) + '%')\n","\n","# add plot and axes labels\n","# set text size using 'fontsize'\n","plt.title('Count Plot for Target Variable (h1n1_vaccine)', fontsize = 15)\n","plt.xlabel('Target Variable', fontsize = 15)\n","plt.ylabel('Count', fontsize = 15)\n","\n","# to show the plot\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vkZahcS9eboQ"},"source":["<a id='correlation'></a>\n","### 4.1.4 Correlation"]},{"cell_type":"markdown","metadata":{"id":"G-aTB0DseboJ"},"source":["<a id='Missing_Values'></a>\n","### 4.1.5 Missing Values"]},{"cell_type":"code","metadata":{"id":"XsY-ydhgeboM"},"source":["# sort the variables on the basis of total null values in the variable\n","# 'isnull().sum()' returns the number of missing values in each variable\n","# 'ascending = False' sorts values in the descending order\n","# the variable with highest number of missing values will appear first\n","Total = df_vaccine.isnull().sum().sort_values(ascending = False)          \n","\n","# calculate the percentage of missing values\n","# 'ascending = False' sorts values in the descending order\n","# the variable with highest percentage of missing values will appear first\n","Percent = (df_vaccine.isnull().sum()*100/df_vaccine.isnull().count()).sort_values(ascending = False)   \n","\n","# concat the 'Total' and 'Percent' columns using 'concat' function\n","# 'keys' is the list of column names\n","# 'axis = 1' concats along the columns\n","missing_data = pd.concat([Total, Percent], axis = 1, keys = ['Total', 'Percentage of Missing Values'])    \n","missing_data"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xKAYv91S7vE8"},"source":["# plot heatmap to check null values\n","# 'cbar = False' does not show the color axis \n","sns.heatmap(df_vaccine.isnull(), cbar=False)\n","\n","# display the plot\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BzggIYx37vE8"},"source":["The horizontal lines in the heatmap correspond to the missing values."]},{"cell_type":"code","metadata":{"collapsed":true,"id":"yuxwnb_L7vE9"},"source":["df_vaccine.drop(['has_health_insur','income_level','dr_recc_h1n1_vacc','dr_recc_seasonal_vacc'], axis=1, inplace=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gdsUWqDg7vE9"},"source":["df_vaccine.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6G7-vWUN7vE9"},"source":["sns.heatmap(df_vaccine.isnull(), cbar=False)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"collapsed":true,"id":"_ncpUZlG7vE-"},"source":["df_vaccine.dropna(axis=0, inplace=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"u48uNnw47vE-"},"source":["df_vaccine.shape"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IBQu8b2Q7vE_"},"source":["After replacing the null values for both the variables, recheck the null values. "]},{"cell_type":"code","metadata":{"id":"NjRktaNN7vE_"},"source":["sns.heatmap(df_vaccine.isnull(), cbar=False)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0ETIKwl47vFA","scrolled":true},"source":["# recheck the null values\n","# 'isnull().sum()' returns the number of missing values in each variable\n","df_vaccine.isnull().sum()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EIcX1xET7vFA"},"source":["<a id='Data_Preparation'></a>\n","## 4.2 Prepare the Data"]},{"cell_type":"markdown","metadata":{"id":"ZwL6c-3F7vFA"},"source":["To build the classification models, we need to encode the categorical variables using dummy encoding."]},{"cell_type":"markdown","metadata":{"id":"aJQzLtVs7vFB"},"source":["**1. Filter numerical and categorical variables **"]},{"cell_type":"markdown","metadata":{"id":"vkCPEpBC7vFB"},"source":["There are no numerical variables except the dependent variable(h1n1_vaccine)"]},{"cell_type":"code","metadata":{"id":"QqFdMQSa7vFB"},"source":["df_vaccine.dtypes"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"collapsed":true,"id":"KeuLbKvq7vFC"},"source":["# create a list of all categorical variables\n","# initiate an empty list to store the categorical variables\n","categorical=[]\n","\n","# use for loop to check the data type of each variable\n","for column in df_vaccine:\n","    \n","    # use 'if' statement with condition to check the categorical type \n","    if is_string_dtype(df_vaccine[column]):\n","        \n","        # append the variables with 'categoric' data type in the list 'categorical'\n","        categorical.append(column)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"collapsed":true,"id":"DLtmzY72eboU"},"source":["# dataframe with categorical features\n","# 'categorical' contains a list of categorical variables\n","df_cat = df_vaccine[categorical]\n","\n","# dataframe with numerical features\n","# use 'drop()' to drop the categorical variables\n","# 'axis = 1' drops the corresponding column(s)\n","df_num = df_vaccine.drop(categorical, axis = 1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"v_gba0-t7vFC"},"source":["**2. Dummy encode the categorical variables**"]},{"cell_type":"code","metadata":{"id":"AEK5HzWz7vFC","scrolled":true},"source":["# print the first five observations of the 'df_cat'\n","df_cat.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"collapsed":true,"id":"rLNKCK7lebo3"},"source":["# use 'get_dummies()' from pandas to create dummy variables\n","# use 'drop_first = True' to create (n-1) dummy variables\n","df_cat_dummies = pd.get_dummies(df_cat, drop_first = True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"u0h3MrwL7vFD"},"source":["# check the first five observations of the data with dummy encoded variables\n","df_cat_dummies.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2MkKCCSY7vFD"},"source":["After removal of missing values and dummy encoding the data, the dataframe `df_cat_dummies` contains all the independent variables and the dataframe df_num contains the target variable. We will rename these dataframes as X and y respectively."]},{"cell_type":"code","metadata":{"collapsed":true,"id":"-mmCt4dT7vFE"},"source":["# df_num contains only the target variable 'h1n1_vaccine'.\n","# We store it in dataframe 'y'\n","y = pd.DataFrame(df_num)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RRzkxu0Y7vFE"},"source":["Now, use this 'y' as a target variable to build the classification models."]},{"cell_type":"code","metadata":{"collapsed":true,"id":"HJ1Nlm1U7vFE"},"source":["# df_cat_dummies contain all the dummy encoded independent variables\n","# We store it in dataframe 'X'\n","X = pd.DataFrame(df_cat_dummies)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_eY4dPCd7vFE"},"source":["# check the first five observations of X\n","X.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_anjdGY57vFF"},"source":["Use this 'X' as a set of predictors to build the classification models."]},{"cell_type":"markdown","metadata":{"id":"hhFgWBRE7vFF"},"source":["#### Create a generalized function to calculate the metrics for the test set."]},{"cell_type":"code","metadata":{"collapsed":true,"id":"g9Wg7zCh7vFF"},"source":["# create a generalized function to calculate the metrics values for test set\n","def get_test_report(model):\n","    \n","    # return the performace measures on test set\n","    return(classification_report(y_test, y_pred))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6eYeFE2z7vFF"},"source":["#### Create a generalized function to calculate the kappa score for the test set."]},{"cell_type":"code","metadata":{"collapsed":true,"id":"Tcy0L3lu7vFG"},"source":["# create a generalized function to calculate the metrics values for test set\n","def kappa_score(model):\n","    \n","    # return the kappa score on test set\n","    return(cohen_kappa_score(y_test, y_pred))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iwypbW4z7vFG"},"source":["#### Define a function to plot the confusion matrix."]},{"cell_type":"code","metadata":{"collapsed":true,"id":"Av39nL7SebpS"},"source":["# define a to plot a confusion matrix for the model\n","def plot_confusion_matrix(model):\n","    \n","    # create a confusion matrix\n","    # pass the actual and predicted target values to the confusion_matrix()\n","    cm = confusion_matrix(y_test, y_pred)\n","\n","    # label the confusion matrix  \n","    # pass the matrix as 'data'\n","    # pass the required column names to the parameter, 'columns'\n","    # pass the required row names to the parameter, 'index'\n","    conf_matrix = pd.DataFrame(data = cm,columns = ['Predicted:0','Predicted:1'], index = ['Actual:0','Actual:1'])\n","\n","    # plot a heatmap to visualize the confusion matrix\n","    # 'annot' prints the value of each grid \n","    # 'fmt = d' returns the integer value in each grid\n","    # 'cmap' assigns color to each grid\n","    # as we do not require different colors for each grid in the heatmap,\n","    # use 'ListedColormap' to assign the specified color to the grid\n","    # 'cbar = False' will not return the color bar to the right side of the heatmap\n","    # 'linewidths' assigns the width to the line that divides each grid\n","    # 'annot_kws = {'size':25})' assigns the font size of the annotated text \n","    sns.heatmap(conf_matrix, annot = True, fmt = 'd', cmap = ListedColormap(['lightskyblue']), cbar = False, \n","                linewidths = 0.1, annot_kws = {'size':25})\n","\n","    # set the font size of x-axis ticks using 'fontsize'\n","    plt.xticks(fontsize = 20)\n","\n","    # set the font size of y-axis ticks using 'fontsize'\n","    plt.yticks(fontsize = 20)\n","\n","    # display the plot\n","    plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YNcsJeZN7vFG"},"source":["#### Define a function to plot the ROC curve."]},{"cell_type":"code","metadata":{"collapsed":true,"id":"f_BftJGq7vFH"},"source":["# define a function to plot the ROC curve and print the ROC-AUC score\n","def plot_roc(model):\n","    \n","    # the roc_curve() returns the values for false positive rate, true positive rate and threshold\n","    # pass the actual target values and predicted probabilities to the function\n","    fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n","\n","    # plot the ROC curve\n","    plt.plot(fpr, tpr)\n","\n","    # set limits for x and y axes\n","    plt.xlim([0.0, 1.0])\n","    plt.ylim([0.0, 1.0])\n","\n","    # plot the straight line showing worst prediction for the model\n","    plt.plot([0, 1], [0, 1],'r--')\n","\n","    # add plot and axes labels\n","    # set text size using 'fontsize'\n","    plt.title('ROC Curve for h1n1_vaccine Classifier', fontsize = 15)\n","    plt.xlabel('False positive rate (1-Specificity)', fontsize = 15)\n","    plt.ylabel('True positive rate (Sensitivity)', fontsize = 15)\n","\n","    # add the AUC score to the plot\n","    # 'x' and 'y' gives position of the text\n","    # 's' is the text \n","    # use round() to round-off the AUC score upto 4 digits\n","    plt.text(x = 0.02, y = 0.9, s = ('AUC Score:',round(roc_auc_score(y_test, y_pred_prob),4)))\n","\n","    # plot the grid\n","    plt.grid(True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gljpR0q47vFH"},"source":["#### Create a generalized function to create a dataframe containing the scores for the models."]},{"cell_type":"code","metadata":{"collapsed":true,"id":"xBtSyL-n7vFH"},"source":["# create an empty dataframe to store the scores for various classification algorithms\n","score_card = pd.DataFrame(columns=['Model', 'AUC Score', 'Precision Score', 'Recall Score', 'Accuracy Score',\n","                                   'Kappa Score', 'f1-score'])\n","\n","# append the result table for all performance scores\n","# performance measures considered for comparision are 'AUC', 'Precision', 'Recall','Accuracy','Kappa Score', and 'f1-score'\n","# compile the required information in a user defined function \n","def update_score_card(model_name):\n","    \n","    # assign 'score_card' as global variable\n","    global score_card\n","\n","    # append the results to the dataframe 'score_card'\n","    # 'ignore_index = True' do not consider the index labels\n","    score_card = score_card.append({'Model': model_name,\n","                                    'AUC Score' : roc_auc_score(y_test, y_pred_prob),\n","                                    'Precision Score': metrics.precision_score(y_test, y_pred),\n","                                    'Recall Score': metrics.recall_score(y_test, y_pred),\n","                                    'Accuracy Score': metrics.accuracy_score(y_test, y_pred),\n","                                    'Kappa Score': cohen_kappa_score(y_test, y_pred),\n","                                    'f1-score': metrics.f1_score(y_test, y_pred)}, \n","                                    ignore_index = True)\n","    return(score_card)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"K1Gqljwv7vFH"},"source":["<a id='LogisticReg'></a>\n","# 5. Logistic Regression "]},{"cell_type":"markdown","metadata":{"id":"_gPLIZwX7vFI"},"source":["Logistic regression is one of the techniques used for classification. The estimates of the parameters are obtained by maximizing the likelihood function."]},{"cell_type":"markdown","metadata":{"id":"yjMQpiVo7vFI"},"source":["<a id='withStatsModels'></a>\n","## 5.1 Logistic Regression (using MLE)"]},{"cell_type":"markdown","metadata":{"id":"e8WQJj3U7vFJ"},"source":["**1. Introduce the intercept term**"]},{"cell_type":"code","metadata":{"id":"pURecTp_7vFJ"},"source":["# add the intercept column using 'add_constant()'\n","X = sm.add_constant(X)\n","\n","# print the first five bservations after adding intercept\n","X.tail()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IMH4cVsm7vFJ"},"source":["**2. Split the dataset into train and test sets**"]},{"cell_type":"code","metadata":{"id":"9XWUmyXrebo_"},"source":["# split data into train subset and test subset\n","# set 'random_state' to generate the same dataset each time you run the code \n","# 'test_size' returns the proportion of data to be included in the test set\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state = 10)\n","\n","# check the dimensions of the train & test subset using 'shape'\n","# print dimension of train set\n","print(\"X_train\",X_train.shape)\n","print(\"y_train\",y_train.shape)\n","\n","# print dimension of test set\n","print(\"X_test\",X_test.shape)\n","print(\"y_test\",y_test.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"t4jkGcXA7vFK"},"source":["#### 3. Build a logistic regression model using statsmodels `Logit()`."]},{"cell_type":"code","metadata":{"id":"MJDiOZWH7vFK","scrolled":false},"source":["# build the model on train data (X_train and y_train)\n","# use fit() to fit the logistic regression model\n","log_reg_model = sm.Logit(y_train, X_train).fit()\n","\n","# print the summary of the model\n","print(log_reg_model.summary())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Wfz46r5b7vFL"},"source":["**Interpretation:** The `Pseudo R-squ.` obtained from the above model summary is the value of `McFadden's R-squared`."]},{"cell_type":"markdown","metadata":{"id":"QsFkUcN57vFL"},"source":["**4. Do predictions on the test set**"]},{"cell_type":"code","metadata":{"id":"UP5DA9_qebpC","scrolled":false},"source":["# let 'y_pred_prob' be the predicted values of y\n","y_pred_prob = log_reg_model.predict(X_test)\n","\n","# print the y_pred_prob\n","y_pred_prob.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"collapsed":true,"id":"s-aj8refebpI"},"source":["# convert probabilities to 0 and 1 using 'if_else'\n","y_pred = ['0' if x < 0.5 else '1' for x in y_pred_prob]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NQyMfFD5ebpP"},"source":["# convert the predicted values to type 'float32'\n","y_pred = np.array(y_pred, dtype=np.float32)\n","\n","# print the first five predictions\n","y_pred[0:5]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7INhAQL97vFN"},"source":["#### 5. Calculate the performance measures."]},{"cell_type":"markdown","metadata":{"id":"GCjzR8Zi7vFN"},"source":["#### Build a confusion matrix."]},{"cell_type":"code","metadata":{"id":"g432iKon7vFN"},"source":["# call the function to plot the confusion matrix\n","# pass the logistic regression model to the function\n","plot_confusion_matrix(log_reg_model)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wrIM_TOq7vFN"},"source":["**Calculate performance measures on the test set.**"]},{"cell_type":"code","metadata":{"id":"YtYS2FnY7vFO","scrolled":false},"source":["# compute the performance measures on test data\n","# call the function 'get_test_report'\n","# pass the logstic regression model to the function\n","test_report = get_test_report(log_reg_model)\n","\n","# print the performace measures\n","print(test_report)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uWHgBGEE7vFO"},"source":["**Interpretation:** The accuracy is 81% for this model. Also, there is significant difference between specificity and sensitivity."]},{"cell_type":"code","metadata":{"id":"61qZlRTM7vFO"},"source":["# compute kappa score on test set\n","# call the function 'kappa_score'\n","# pass the logstic regression model to the function\n","kappa_value = kappa_score(log_reg_model)\n","\n","# print the kappa value\n","print(kappa_value)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"E9e-h6sl7vFP"},"source":["**Interpretation:** As the kappa score for the logistic regression is 0.3426, we can say that there is low to moderate agreement between the actual and predicted values."]},{"cell_type":"markdown","metadata":{"id":"7w8SUsfR7vFP"},"source":["**Plot the ROC curve.**"]},{"cell_type":"code","metadata":{"id":"7RX99udT7vFP","scrolled":false},"source":["# call the function 'plot_roc' to plot the ROC curve\n","# pass the logstic regression model to the function\n","plot_roc(log_reg_model)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mWWF89fN7vFQ"},"source":["**6. Tabulate the results.**"]},{"cell_type":"markdown","metadata":{"id":"-gebjPFK7vFQ"},"source":["Now, we tabulate the results, so that is easy for us to compare the models built."]},{"cell_type":"code","metadata":{"id":"58KkcSiLWuQ3"},"source":["# use the function 'update_score_card' to store the performance measures\n","# pass the 'Logistic Regression' as model name to the function\n","update_score_card(model_name = 'Logistic RegressionMLE')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"chj2_KBtebpz"},"source":["<a id='usingSGD'></a>\n","## 5.2 Logistic Regression (using SGD)"]},{"cell_type":"markdown","metadata":{"id":"Few5bXkx7vFS"},"source":["**1. Scale the data features**"]},{"cell_type":"markdown","metadata":{"id":"P2XmhElZ7vFS"},"source":["We do not need to scale the data, as all the varaibles are categorical variables."]},{"cell_type":"markdown","metadata":{"id":"bWJ04QRq7vFS"},"source":["**2. Split the data into training and test sets**"]},{"cell_type":"markdown","metadata":{"id":"y_9R6mIU7vFS"},"source":["The data has been split in section 5.1"]},{"cell_type":"markdown","metadata":{"id":"yGX-ftJt7vFT"},"source":["**3. Build the model**\n","\n","The `SGDClassifier()` from sklearn contains an intercept term. Thus, there is no need to add the column of intercept."]},{"cell_type":"code","metadata":{"collapsed":true,"id":"OeNBFnOQebp1"},"source":["# instantiate the 'SGDClassifier' to build model using SGD\n","# to perform logistic regression, consider the log-loss function \n","# set 'random_state' to generate the same dataset each time you run the code \n","SGD = SGDClassifier(loss = 'log', random_state = 10)\n","\n","# fit the model on scaled training data\n","logreg_with_SGD = SGD.fit(X_train, y_train)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cORF-yLG7vFT"},"source":["**4. Do predictions on the test set**"]},{"cell_type":"code","metadata":{"collapsed":true,"id":"Yj7qPoBY7vFT"},"source":["# predict probabilities on the test set\n","# consider the probability of positive class by subsetting with '[:,1]'\n","y_pred_prob = logreg_with_SGD.predict_proba(X_test)[:,1]\n","#y_pred_prob = logreg_with_SGD.predict_proba(X_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XlG-T_TrCz-x"},"source":["y_pred_prob"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VWh3BJav__Vd"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sa0mHHfDACNb"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0fRxa5HYAQin"},"source":["y_pred_prob"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NqnipyEw_zbl"},"source":["#X_test.head(2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"V_uZv116_cjq"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"collapsed":true,"id":"gffKl1JR7vFT"},"source":["# use predict() to predict the class labels of target variable\n","y_pred = logreg_with_SGD.predict(X_test)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TaB-DPwM7vFU"},"source":["**5. Compute accuracy measures**"]},{"cell_type":"markdown","metadata":{"id":"RTajRkkK7vFU"},"source":["#### Build a confusion matrix."]},{"cell_type":"code","metadata":{"id":"1dvHYmaw7vFU"},"source":["# call the function to plot the confusion matrix\n","# pass the logistic regression (SGD) model to the function\n","plot_confusion_matrix(logreg_with_SGD)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1KyphZ6-7vFU"},"source":["**Calculate performance measures on the test set.**"]},{"cell_type":"code","metadata":{"id":"AMQFVyUC7vFV","scrolled":false},"source":["# compute the performance measures on test data\n","# call the function 'get_test_report'\n","# pass the logstic regression (SGD) model to the function\n","test_report = get_test_report(logreg_with_SGD)\n","\n","# print the performace measures\n","print(test_report)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EN042rxd7vFV"},"source":["**Interpretation:** The accuracy is 81% for this model."]},{"cell_type":"code","metadata":{"id":"8IvqdCmD7vFV"},"source":["# compute kappa score on test set\n","# call the function 'kappa_score'\n","# pass the logstic regression (SGD) model to the function\n","kappa_value = kappa_score(logreg_with_SGD)\n","\n","# print the kappa value\n","print(kappa_value)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"s02jrWaY7vFW"},"source":["**Interpretation:** As the kappa score for the logistic regression (SGD) is 0.3047, we can say that there is low to moderate agreement between the actual and predicted values."]},{"cell_type":"markdown","metadata":{"id":"Rn41xl9q7vFW"},"source":["**Plot the ROC curve.**"]},{"cell_type":"code","metadata":{"id":"IPGRGQok7vFW","scrolled":false},"source":["# call the function 'plot_roc' to plot the ROC curve\n","# pass the logstic regression (SGD) model to the function\n","plot_roc(logreg_with_SGD)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oAxsFXaT7vFX"},"source":["**6. Tabulate the results**"]},{"cell_type":"code","metadata":{"id":"6ZbEhULV7vFX"},"source":["# use the function 'update_score_card' to store the performance measures\n","# pass the 'Logistic Regression (SGD)' as model name to the function\n","update_score_card(model_name = 'Logistic Regression (SGD)')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IXEtjDtt7vFX"},"source":["<a id=\"conclusion\"> </a>\n","# 6. Conclusion and Interpretation"]},{"cell_type":"markdown","metadata":{"id":"nA65Fq5J7vFY"},"source":["To take the final conclusion, let us print the result table."]},{"cell_type":"code","metadata":{"id":"nwR4TzUv7vFY"},"source":["# print the 'score_card' to compare all the models\n","score_card"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7dsxrEU77vFY"},"source":["Let us plot the performance measures of the two models in the single graph."]},{"cell_type":"code","metadata":{"id":"HgEQMDlN7vFZ"},"source":["# plot the graph\n","# by default, plot() returns the line plot\n","score_card.plot()\n","\n","# set the text size of the title\n","plt.title(label = 'Comparison of the Models', fontsize = 15)\n","\n","# set the model names as x-ticks\n","# 'score_card.Model' retuns the model names\n","# rotate the x-axis labels vertically\n","plt.xticks([0,1], list(score_card.Model), rotation = 'vertical')\n","\n","# display the plot\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dgUi7oVfOD1Y"},"source":["<a id='usingSGD'></a>\n","## 5.3 Logistic Regression (using sklearn), Applying ROC threholds to improve the Model"]},{"cell_type":"markdown","metadata":{"id":"8EG-Cs49GUkS"},"source":["Applying ROC threholds to improve the Model is not required when you are using the Sklearn Method. You use it only if you have a Business Reason to do it. "]},{"cell_type":"code","metadata":{"id":"wPlKYCHHGpNd"},"source":["X1 = pd.DataFrame(df_cat_dummies)\n","X1.head(5)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jSVqDF1FGpQk"},"source":["Y1 = pd.DataFrame(df_num)\n","Y1.head(5)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ls8ICjLrGpZA"},"source":["# split X and y into training and testing sets\n","from sklearn.model_selection import train_test_split\n","#from sklearn.model_selection import cross_val_score\n","\n","#from sklearn.cross_validation import train_test_split\n","X_train,X_test,y_train,y_test=train_test_split(X1,Y1,test_size=0.2,random_state=10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HQ8wyhGuGpdh"},"source":["# build the model on train data (X_train and y_train)\n","model = LogisticRegression()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qkTj32IHH4Zj"},"source":["# fit the model with data\n","model.fit(X_train,y_train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xFtR6MuREpQw"},"source":["y_pred = model.predict(X_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"H4nF4R7eEpjt"},"source":["plot_confusion_matrix(model)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DTnxATQ1E1k2"},"source":["# compute the performance measures on test data\n","# call the function 'get_test_report'\n","# pass the logstic regression model to the function\n","test_report = get_test_report(model)\n","\n","# print the performace measures\n","print(test_report)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0Y2wDZObE1rQ"},"source":["model.predict_proba(X_test)[:10,1:]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iYbBZ6dCHdO6"},"source":["y_pred_prob = model.predict_proba(X_test)[:,1]\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DqnSI__8NBNF"},"source":["y_pred_prob[0:10]    #probability values after changing the threshold"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dX960MPVH5m8"},"source":["y_pred = model.predict(X_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Fwi9qTnXJH_o"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sbTxPVapJJGu"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EmwzUlqXIwU0"},"source":["#### 5. Calculate the performance measures."]},{"cell_type":"markdown","metadata":{"id":"SAjP5w6WIwU1"},"source":["#### Build a confusion matrix."]},{"cell_type":"code","metadata":{"id":"TZVBA3QdIwU2"},"source":["# call the function to plot the confusion matrix\n","# pass the logistic regression model to the function\n","#plot_confusion_matrix(model)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"clGNJhJcIwU3"},"source":["**Calculate performance measures on the test set.**"]},{"cell_type":"code","metadata":{"id":"otv5p6A_IwU4","scrolled":false},"source":["# compute the performance measures on test data\n","# call the function 'get_test_report'\n","# pass the logstic regression model to the function\n","#test_report = get_test_report(model)\n","\n","# print the performace measures\n","#print(test_report)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2fbiC37-IwU6"},"source":["# compute kappa score on test set\n","# call the function 'kappa_score'\n","# pass the logstic regression model to the function\n","kappa_value = kappa_score(model)\n","\n","# print the kappa value\n","print(kappa_value)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LIav7MQrIwU7"},"source":["**Interpretation:** As the kappa score for the logistic regression is 0.3424, we can say that there is low to moderate agreement between the actual and predicted values."]},{"cell_type":"markdown","metadata":{"id":"KRVKNQraIwU8"},"source":["**Plot the ROC curve.**"]},{"cell_type":"code","metadata":{"id":"xw_Vh8lUIwU9","scrolled":false},"source":["# call the function 'plot_roc' to plot the ROC curve\n","# pass the logstic regression model to the function\n","plot_roc(model)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"R0h5twlVbO_c"},"source":["<font color=\"red\">\n","The Y-axis of the ROC graph denotes the True Positive Rate, also called as Sensitivity. The X-axis of the ROC graph denotes the False Positive Rate. <br>  \n","</font>  "]},{"cell_type":"code","metadata":{"id":"fQUaWOOqqTc0"},"source":["roc_auc_score(y_test,y_pred_prob)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5V-zR-gUIwU_"},"source":["**6. Tabulate the results.**"]},{"cell_type":"markdown","metadata":{"id":"OlC00sIHIwU_"},"source":["Now, we tabulate the results, so that is easy for us to compare the models built."]},{"cell_type":"code","metadata":{"id":"fni-TDqoN-3L"},"source":["# use the function 'update_score_card' to store the performance measures\n","# pass the 'Logistic Regression' as model name to the function\n","update_score_card(model_name = 'Logistic Regression default (sklearn)')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mKOaRoocIw76"},"source":["model.predict_proba(X_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1eICHwyHNuiv"},"source":["score_card"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jI9sA3xC3R4J"},"source":["<a id=\"conclusion\"> </a>\n","# 5.3.1 To show ROC Curve with Different Threshold Values"]},{"cell_type":"markdown","metadata":{"id":"_Y9M2C8P6KWf"},"source":["THRESHOLD VALUE = 0.5"]},{"cell_type":"code","metadata":{"id":"eNhL4RIfCfAM"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xiRW2jsd3nNc"},"source":["# build the model on train data (X_train and y_train)\n","modelp5 = LogisticRegression()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vTwTmL5a3nNm"},"source":["# fit the model with data\n","modelp5.fit(X_train,y_train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sQRm8ewf3nNq"},"source":["modelp5.predict_proba(X_test)[:10,1:]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cMPYYyER3nNv"},"source":["y_pred_prob = (modelp5.predict_proba(X_test)[:,1]>0.5).astype(int)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6e3PtPGj3nNw"},"source":["y_pred_prob[0:10]    #probability values after changing the threshold"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ni-fVhXR3nNx"},"source":["y_pred = modelp5.predict(X_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oaq6Ttn-3nNy"},"source":["# convert probabilities to 0 and 1 using 'if_else'\n","y_pred = ['0' if x < 0.5 else '1' for x in y_pred_prob]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tzogHR003nOC"},"source":["**Plot the ROC curve.**"]},{"cell_type":"code","metadata":{"id":"b8Yq5drb3nOD","scrolled":false},"source":["# call the function 'plot_roc' to plot the ROC curve\n","# pass the logstic regression model to the function\n","plot_roc(modelp5)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"T5QwwXrw3nOF"},"source":["roc_auc_score(y_test,y_pred_prob)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hr6MyLIE6l-6"},"source":["THRESHOLD VALUE = 0.75"]},{"cell_type":"code","metadata":{"id":"M5PPbKYx6BT5"},"source":["# build the model on train data (X_train and y_train)\n","modelp75 = LogisticRegression()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GgOzSk2w6BUg"},"source":["# fit the model with data\n","modelp75.fit(X_train,y_train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VnoMqq5p6BUj"},"source":["modelp75.predict_proba(X_test)[:10,1:]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Tmuv5slD6BUk"},"source":["y_pred_prob = (modelp75.predict_proba(X_test)[:,1]>0.75).astype(int)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9dugn3KL6BUl"},"source":["y_pred_prob[0:10]    #probability values after changing the threshold"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XsU5bKwu6BUn"},"source":["y_pred = modelp75.predict(X_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JHA5E_JN6BUo"},"source":["# convert probabilities to 0 and 1 using 'if_else'\n","y_pred = ['0' if x < 0.75 else '1' for x in y_pred_prob]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5w56TCq26BUq"},"source":["**Plot the ROC curve.**"]},{"cell_type":"code","metadata":{"id":"J7rdd7CI6BUr","scrolled":false},"source":["# call the function 'plot_roc' to plot the ROC curve\n","# pass the logstic regression model to the function\n","plot_roc(modelp75)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"weTREQDn7BVV"},"source":["roc_auc_score(y_test,y_pred_prob)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kezUI4b17dm3"},"source":["<a id=\"conclusion\"> </a>\n","# 6. Conclusion and Interpretation"]},{"cell_type":"markdown","metadata":{"id":"7FdIHFPcBa6X"},"source":["<font color=\"red\">\n","The dotted line indicates equal number of true positives and false positives. The more the blue line lies away from the dotted line, the more better is our model classification. The farther blue line indicates higher True Positive Rate, i.e. maximum number of observations are correctly classified.\n","</font>"]}]}